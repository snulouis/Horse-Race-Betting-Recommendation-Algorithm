{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "\n",
    "from horse_dataset import HorseDataset\n",
    "from winning_set import WinningSetModule, send_next_layer\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, optimizer, n_iters): \n",
    "    model.to(device=device)\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    print_every = 10\n",
    "    for e in range(n_iters):\n",
    "        for i, (x, y) in enumerate(dataset):\n",
    "            x = x.to(device=device)\n",
    "            y = (len(y[0]) - y.type(torch.float32)) / (len(y[0]) - 1)\n",
    "            y = (torch.exp(y) - 1) / 1.72\n",
    "            y = y.to(device=device)\n",
    "            model.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = loss_fcn(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if e % print_every == 0:\n",
    "            print('(%d %d%%) %.4f' % (e, e / n_iters * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_helper(model, x):\n",
    "    batch_size = len(x)\n",
    "    output = model(x)\n",
    "    result = [None for _ in range(batch_size)]\n",
    "    recommand_lanes = torch.sort(torch.topk(output, 7, sorted=False)[1])[0]\n",
    "    for index in range(batch_size):\n",
    "        result[index] = x[index, recommand_lanes[index]]\n",
    "    return torch.stack(tuple(result)), recommand_lanes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n",
      "[2094, 232]\n",
      "(0 0%) 0.0959\n",
      "(10 33%) 0.0668\n",
      "(20 66%) 0.0654\n",
      "lane size: 8, top 7 accuarcy_1: 0.9033251231527094%, 232\n",
      "lane size: 8, top 7 accuarcy_2: 0.3232758620689655%, 232\n",
      "lane size: 8, top 3 accuarcy_1: 0.9784482758620688%, 232\n",
      "lane size: 8, top 3 accuarcy_2: 0.9353448275862069%, 232\n",
      "[2703, 300]\n",
      "(0 0%) 0.0941\n",
      "(10 33%) 0.0806\n",
      "(20 66%) 0.0620\n",
      "lane size: 9, top 7 accuarcy_1: 0.8519047619047618%, 300\n",
      "lane size: 9, top 7 accuarcy_2: 0.15%, 300\n",
      "lane size: 9, top 3 accuarcy_1: 0.96%, 300\n",
      "lane size: 9, top 3 accuarcy_2: 0.8833333333333333%, 300\n"
     ]
    }
   ],
   "source": [
    "print('using device:', device)\n",
    "loss_fcn = nn.MSELoss()\n",
    "\n",
    "model = WinningSetModule(9, 8, 14)\n",
    "_size = 8\n",
    "\n",
    "n_iters = 30\n",
    "\n",
    "test_data_saved = []\n",
    "train_data_saved = []\n",
    "\n",
    "for _size in range(8, 15):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    dataset = HorseDataset(f'./preprocess/data/data_{_size:02}.pkl')\n",
    "    _dataset_size = len(dataset)\n",
    "    _test_data_size = _dataset_size // 10\n",
    "    _train_data_size = _dataset_size - _test_data_size\n",
    "    \n",
    "    #print([_train_data_size, _test_data_size])\n",
    "    \n",
    "    train_dataset, test_dataset = random_split(dataset, [_train_data_size, _test_data_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    train(train_loader, model, optimizer, n_iters)\n",
    "    \n",
    "    test_data_saved.append(test_loader) # test를 추출합니다\n",
    "    train_data_saved.append(train_loader) # train를 추출합니다\n",
    "\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 7\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([sum([1 if (val in result[index]) else 0 for val in predicted[index]]) for index in range(len(x))]) / sc\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 7 accuarcy_1: {s / total}%, {total}')\n",
    "\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 7\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([1 if (sum([1 if (val in result[index]) else 0 for val in predicted[index]]) == sc) else 0 for index in range(len(x))])\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 7 accuarcy_2: {s / total}%, {total}')\n",
    "    \n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 3\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([sum([1 if (val in result[index]) else 0 for val in predicted[index]]) for index in range(len(x))]) / sc\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 3 accuarcy_1: {s / total}%, {total}')\n",
    "    \n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 3\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([1 if (sum([1 if (val in result[index]) else 0 for val in predicted[index]]) == sc) else 0 for index in range(len(x))])\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 3 accuarcy_2: {s / total}%, {total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'fng_pt2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WinningSetModule(9, 8, 14)\n",
    "model.load_state_dict(torch.load('fng_pt2.pt', map_location=device))\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane size: 8, top 3 accuarcy_1: 0.9819432502149611%, 2326\n",
      "lane size: 8, top 3 accuarcy_2: 0.945829750644884%, 2326\n",
      "lane size: 9, top 3 accuarcy_1: 0.9615939615939615%, 3003\n",
      "lane size: 9, top 3 accuarcy_2: 0.8867798867798867%, 3003\n",
      "lane size: 10, top 3 accuarcy_1: 0.9440077632217366%, 3435\n",
      "lane size: 10, top 3 accuarcy_2: 0.8395924308588064%, 3435\n",
      "lane size: 11, top 3 accuarcy_1: 0.9230941704035872%, 4460\n",
      "lane size: 11, top 3 accuarcy_2: 0.7838565022421524%, 4460\n",
      "lane size: 12, top 3 accuarcy_1: 0.9089869474348355%, 8453\n",
      "lane size: 12, top 3 accuarcy_2: 0.747426949012185%, 8453\n",
      "lane size: 13, top 3 accuarcy_1: 0.9009157509157512%, 1820\n",
      "lane size: 13, top 3 accuarcy_2: 0.7263736263736263%, 1820\n",
      "lane size: 14, top 3 accuarcy_1: 0.8785564540281517%, 4452\n",
      "lane size: 14, top 3 accuarcy_2: 0.672282120395328%, 4452\n"
     ]
    }
   ],
   "source": [
    "for _size in range(8, 15):\n",
    "    dataset = HorseDataset(f'./preprocess/data/data_{_size:02}.pkl')\n",
    "    _loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 3\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([sum([1 if (val in result[index]) else 0 for val in predicted[index]]) for index in range(len(x))]) / sc\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 3 accuarcy_1: {s / total}%, {total}')\n",
    "    \n",
    "    s = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = -y\n",
    "        y = y.to(device=device)\n",
    "        output = model(x)\n",
    "        predicted = torch.topk(output, 7, sorted=False)[1]\n",
    "        sc = 3\n",
    "        result = torch.topk(y, sc, sorted=False)[1]\n",
    "        s += sum([1 if (sum([1 if (val in result[index]) else 0 for val in predicted[index]]) == sc) else 0 for index in range(len(x))])\n",
    "        total += len(y)\n",
    "    print(f'lane size: {_size}, top 3 accuarcy_2: {s / total}%, {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([32, 8, 9])\n",
      "torch.Size([8, 8, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([32, 9, 9])\n",
      "torch.Size([12, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(test_data_saved[0]):\n",
    "    print(x.shape)\n",
    "for i, (x, y) in enumerate(test_data_saved[1]):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
