{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from horse_dataset import HorseDataset\n",
    "from winning_set import WinningSetModule, send_next_layer\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_train(dataset, model, optimizer, n_iters, test): \n",
    "    if test :\n",
    "        \n",
    "        res_x = []\n",
    "        res_y = []\n",
    "        res_z = []\n",
    "\n",
    "        model.to(device=device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y, z) in enumerate(dataset):\n",
    "                x = x.to(device=device)\n",
    "                \n",
    "                output = model(x)\n",
    "                if output.shape[0] != 32 :\n",
    "                    break\n",
    "\n",
    "                for j in range(len(output)): #batch num\n",
    "                    out_x = []\n",
    "                    out_y = []\n",
    "                    out_z = []\n",
    "                    \n",
    "                    index = output[j].argsort()\n",
    "                    dex = np.zeros(100)\n",
    "#                     for k in range(len(index)): #lane\n",
    "#                         if index[k] >= 7 : \n",
    "#                             dex[index[k]] = 0\n",
    "#                         else :\n",
    "#                             dex[index[k]] = 1\n",
    "                    for k in range(len(index)): #lane\n",
    "                         if index[k] < 7:\n",
    "                            out_x.append(x[j][index[k]])\n",
    "                            out_y.append(y[j][index[k]])\n",
    "                            out_z.append(z[j][index[k]])\n",
    "#                         if dex[k] == 1 : \n",
    "#                             out_x.append(x[j][k])\n",
    "#                             out_y.append(y[j][k])\n",
    "                            #out_z.append(z[j][k])\n",
    "                        \n",
    "                    res_x.append(out_x)\n",
    "                    res_y.append(out_y)\n",
    "                    res_z.append(out_z)\n",
    "            \n",
    "            return res_x, res_y, res_z\n",
    "                \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "        \n",
    "    else :\n",
    "        model.to(device=device)\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        print_every = 10\n",
    "        for e in range(n_iters):\n",
    "            for i, (x, y, z) in enumerate(dataset):\n",
    "                x = x.to(device=device)\n",
    "                y = (len(y[0]) - y.type(torch.float32)) / (len(y[0]) - 1)\n",
    "                y = (torch.exp(y) - 1) / 1.72\n",
    "                y = y.to(device=device)\n",
    "                model.zero_grad()\n",
    "                output = model(x)\n",
    "                loss = loss_fcn(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if e % print_every == 0:\n",
    "                print('(%d %d%%) %.4f' % (e, e / n_iters * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 0%) 0.1048\n",
      "(10 33%) 0.0615\n",
      "(20 66%) 0.0618\n",
      "(0 0%) 0.1109\n",
      "(10 33%) 0.0678\n",
      "(20 66%) 0.0450\n",
      "(0 0%) 0.1017\n",
      "(10 33%) 0.0700\n",
      "(20 66%) 0.0631\n",
      "(0 0%) 0.1016\n",
      "(10 33%) 0.0629\n",
      "(20 66%) 0.0535\n",
      "(0 0%) 0.0893\n",
      "(10 33%) 0.0642\n",
      "(20 66%) 0.0682\n",
      "(0 0%) 0.1016\n",
      "(10 33%) 0.0843\n",
      "(20 66%) 0.0735\n",
      "(0 0%) 0.0942\n",
      "(10 33%) 0.0657\n",
      "(20 66%) 0.0575\n"
     ]
    }
   ],
   "source": [
    "loss_fcn = nn.MSELoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "w_model = WinningSetModule(9, 8, 14)\n",
    "\n",
    "n_iters = 30\n",
    "\n",
    "test_data_saved = []\n",
    "train_data_saved = []\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "test_z = []\n",
    "\n",
    "for _size in range(7, 8):\n",
    "    w_optimizer = torch.optim.Adam(w_model.parameters(), lr=0.001)\n",
    "    dataset = HorseDataset(f'./preprocess/data/data_{_size:02}.pkl')\n",
    "    _dataset_size = len(dataset)\n",
    "    _test_data_size = _dataset_size // 10\n",
    "    _train_data_size = _dataset_size - _test_data_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [_train_data_size, _test_data_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i, (x,y,z) in enumerate(train_loader):\n",
    "\n",
    "        if len(x) != 32 :\n",
    "            break\n",
    "        for j in range(32):\n",
    "            train_x.append(x[j])\n",
    "            train_y.append(y[j])\n",
    "        \n",
    "    for i, (x,y,z) in enumerate(test_loader):\n",
    "        if len(x) != 32 :\n",
    "            break\n",
    "        for j in range(32):\n",
    "            test_x.append(x[j])\n",
    "            test_y.append(y[j])\n",
    "            test_z.append(z[j])\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "for _size in range(8, 15):\n",
    "    w_optimizer = torch.optim.Adam(w_model.parameters(), lr=0.001)\n",
    "    dataset = HorseDataset(f'./preprocess/data/data_{_size:02}.pkl')\n",
    "    _dataset_size = len(dataset)\n",
    "    _test_data_size = _dataset_size // 10\n",
    "    _train_data_size = _dataset_size - _test_data_size\n",
    "    \n",
    "    \n",
    "    train_dataset, test_dataset = random_split(dataset, [_train_data_size, _test_data_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    w_train(train_loader, w_model, w_optimizer, n_iters, 0) # training 합니다. IMPORTANT!!!\n",
    "     \n",
    "    train_data_saved.append(train_loader) # train를 추출합니다\n",
    "    test_data_saved.append(test_loader) # test를 추출합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Horse_1st(nn.Module):\n",
    "    def __init__(self, lane):\n",
    "        super(Horse_1st, self).__init__()\n",
    "        self.fc1 = nn.Linear(9*lane,100)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(100,lane)        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.lane = lane\n",
    "        \n",
    "    def forward(self, x):\n",
    "      x = x.view(-1, 9*self.lane)\n",
    "      x = self.fc1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.relu1(x)\n",
    "      x = self.fc2(x)\n",
    "      x = self.bn2(x)\n",
    "      x = self.relu2(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc3(x)\n",
    "      out = self.softmax(x)\n",
    "\n",
    "      return out\n",
    "\n",
    "class Horse_2nd(nn.Module):\n",
    "    def __init__(self, lane):\n",
    "        super(Horse_2nd, self).__init__()\n",
    "        self.fc1 = nn.Linear(9*lane,100)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(100,lane) \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.lane = lane\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = x.view(-1, 9*self.lane)\n",
    "      x = self.fc1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.relu1(x)\n",
    "      x = self.fc2(x)\n",
    "      x = self.bn2(x)\n",
    "      x = self.relu2(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc3(x)\n",
    "      out = self.softmax(x)\n",
    "\n",
    "      return out\n",
    "    \n",
    "class Horse_3rd(nn.Module):\n",
    "    def __init__(self, lane):\n",
    "        super(Horse_3rd, self).__init__()\n",
    "        self.fc1 = nn.Linear(9*lane,100)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(100,lane)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.lane = lane\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = x.view(-1, 9*self.lane)\n",
    "      x = self.fc1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.relu1(x)\n",
    "      x = self.fc2(x)\n",
    "      x = self.bn2(x)\n",
    "      x = self.relu2(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc3(x)\n",
    "      out = self.softmax(x)\n",
    "\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def r_train(data_x, data_y, model, rank, lane, criterion, optimizer, num_epochs, test): \n",
    "    if test : \n",
    "        model.eval()\n",
    "        acc = 0\n",
    "        result = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(int(len(data_x)/32)):\n",
    "                x = data_x[i*32:(i+1)*32]\n",
    "                y = data_y[i*32:(i+1)*32]\n",
    "                \n",
    "                \n",
    "                for k in range(len(x)):\n",
    "                    for l in range(len(x[k])):\n",
    "                        if l == 0 :\n",
    "                            X = x[k][l].view(1,-1)\n",
    "                        else :\n",
    "                            X = torch.cat((X,x[k][l].view(1,-1)), dim=0)\n",
    "                    if k == 0:\n",
    "                        Y = X.view(1,7,-1)\n",
    "                    else :\n",
    "                        Y = torch.cat((Y,X.view(1,7,-1)), dim=0)\n",
    "                \n",
    "                x = torch.FloatTensor(Y) #np.asarray(x, dtype=np.float64)\n",
    "                x = x.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x)\n",
    "                \n",
    "                for k in range(len(outputs)):\n",
    "                    result.append(outputs[k])\n",
    "\n",
    "                rank_horse_list = []\n",
    "                for batch_no in range(32):\n",
    "                    rank_horse = []\n",
    "                    for horse_no in range(lane):\n",
    "                        if y[batch_no][horse_no] == rank:\n",
    "                            rank_horse.append(1)\n",
    "                        else:\n",
    "                            rank_horse.append(0)\n",
    "\n",
    "                    rank_horse_list.append(rank_horse)\n",
    "\n",
    "                rank_horse_list = torch.FloatTensor(rank_horse_list)\n",
    "                rank_horse_list = rank_horse_list.to(device)\n",
    "                \n",
    "\n",
    "                for j in range(len(y)):\n",
    "                    if rank_horse_list.argmax(1)[j] == outputs.argmax(1)[j]:\n",
    "                        acc += 1\n",
    "\n",
    "            print(\"ACCURACY [%d/%d], %.4f\"\n",
    "                  %(acc, (int(len(data_x)/32)*32), acc/(int(len(data_x)/32)*32)))\n",
    "\n",
    "            return result\n",
    "\n",
    "    else : \n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(int(len(data_x)/32)):\n",
    "                x = data_x[i*32:(i+1)*32]\n",
    "                y = data_y[i*32:(i+1)*32]\n",
    "                \n",
    "                \n",
    "                for k in range(len(x)):\n",
    "                    for l in range(len(x[k])):\n",
    "                        if l == 0 :\n",
    "                            X = x[k][l].view(1,-1)\n",
    "                        else :\n",
    "                            X = torch.cat((X,x[k][l].view(1,-1)), dim=0)\n",
    "                    if k == 0:\n",
    "                        Y = X.view(1,7,-1)\n",
    "                    else :\n",
    "                        Y = torch.cat((Y,X.view(1,7,-1)), dim=0)\n",
    "                \n",
    "                x = torch.FloatTensor(Y) #np.asarray(x, dtype=np.float64)\n",
    "                x = x.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(x)\n",
    "                \n",
    "                rank_horse_list = []\n",
    "                for batch_no in range(32):\n",
    "                    rank_horse = []\n",
    "                    for horse_no in range(lane):\n",
    "                        if y[batch_no][horse_no] == rank:\n",
    "                            rank_horse.append(1)\n",
    "                        else:\n",
    "                            rank_horse.append(0)\n",
    "\n",
    "                    rank_horse_list.append(rank_horse)\n",
    "\n",
    "                rank_horse_list = torch.FloatTensor(rank_horse_list)\n",
    "                rank_horse_list=rank_horse_list.to(device)\n",
    "\n",
    "                loss = criterion(outputs, rank_horse_list)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(loss)\n",
    "                \n",
    "#         if (epoch+1) % 10 == 0 :\n",
    "#             print(epoch)\n",
    "#                 print(\"loss : %.4f\"\n",
    "#                       %(loss))\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(len(train_data_saved)):\n",
    "\n",
    "    res_x, res_y, _ = w_train(train_data_saved[i], w_model, w_optimizer, 1, 1)\n",
    "    \n",
    "    for j in range(len(res_x)):\n",
    "        train_x.append(res_x[j])\n",
    "        train_y.append(res_y[j])\n",
    "            \n",
    "\n",
    "print(len(train_x))\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TX = []\n",
    "TY = []\n",
    "TZ = []\n",
    "for i in range(len(test_data_saved)):\n",
    "    res_x, res_y, res_z = w_train(test_data_saved[i], w_model, w_optimizer, 1, 1)\n",
    "    tx = []\n",
    "    ty = []\n",
    "    tz = []\n",
    "    for j in range(len(res_x)):\n",
    "        tx.append(res_x[j])\n",
    "        ty.append(res_y[j])\n",
    "        tz.append(res_z[j])\n",
    "    TX.append(tx)\n",
    "    TY.append(ty)\n",
    "    TZ.append(tz)\n",
    "    \n",
    "print(len(test_x))\n",
    "            \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0697, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0701, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0683, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0671, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0651, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0660, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0652, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0560, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0569, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0532, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0644, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0635, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0628, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0623, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0628, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0645, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "num_epochs = 10 # 100\n",
    "\n",
    "model_1st = Horse_1st(7)\n",
    "model_1st.to(device)\n",
    "\n",
    "model_2nd = Horse_2nd(7)\n",
    "model_2nd.to(device)\n",
    "\n",
    "model_3rd = Horse_3rd(7)\n",
    "model_3rd.to(device)\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(model_1st.parameters(), lr=0.001)\n",
    "optimizer_2 = torch.optim.Adam(model_2nd.parameters(), lr=0.001)\n",
    "optimizer_3 = torch.optim.Adam(model_3rd.parameters(), lr=0.001)\n",
    "\n",
    "r_train(train_x, train_y, model_1st, 1, 7, criterion, optimizer_1, num_epochs, 0) \n",
    "r_train(train_x, train_y, model_2nd, 2, 7, criterion, optimizer_2, num_epochs, 0) \n",
    "r_train(train_x, train_y, model_3rd, 3, 7, criterion, optimizer_3, num_epochs, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY [31/96], 0.3229\n",
      "ACCURACY [30/96], 0.3125\n",
      "ACCURACY [12/96], 0.1250\n",
      "4.8979172706604\n",
      "3.4552080631256104\n"
     ]
    }
   ],
   "source": [
    "conf_1 = r_train(test_x, test_y, model_1st, 1, 7, criterion, optimizer_1, num_epochs, 1) \n",
    "conf_2 = r_train(test_x, test_y, model_2nd, 2, 7, criterion, optimizer_2, num_epochs, 1) \n",
    "conf_3 = r_train(test_x, test_y, model_3rd, 3, 7, criterion, optimizer_3, num_epochs, 1) \n",
    "\n",
    "\n",
    "net = 0\n",
    "exp = 0\n",
    "\n",
    "#단승 기대 수익률\n",
    "for i in range(len(conf_1)):\n",
    "    temp = []\n",
    "    for j in range(len(conf_1[i])):\n",
    "        temp.append(conf_1[i][j])\n",
    "\n",
    "    temp = torch.Tensor(temp)\n",
    "#     for j in range(len(temp)):\n",
    "#         temp[j] = temp[j] #* test_z[i][j][0].item() \n",
    "    bet = temp.argmax(0).item()\n",
    "\n",
    "    net += test_z[i][j][0].item() * ( test_y[i][bet] < 2 )  #실제 수익\n",
    "    \n",
    "    #test_x[i][bet][5].item() 이게 연승 배당률인데 정규화 되어있고 어떤 col인지 모름\n",
    "\n",
    "exp = net / len(conf_1)\n",
    "\n",
    "print(exp.item())\n",
    "\n",
    "net = 0\n",
    "exp = 0\n",
    "\n",
    "#연승 기대 수익률\n",
    "for i in range(len(conf_1)):\n",
    "\n",
    "    temp = []\n",
    "    for j in range(len(conf_1[i])):\n",
    "        temp.append(1-(1-conf_1[i][j])*(1-conf_2[i][j])*(1-conf_2[i][j]))\n",
    "\n",
    "    temp = torch.Tensor(temp)\n",
    "#     for j in range(len(temp)):\n",
    "#         temp[j] = temp[j] #* test_z[i][j][1].item() \n",
    "    bet = temp.argmax(0).item()\n",
    "\n",
    "    net += test_z[i][j][1].item()  * ( test_y[i][bet] <= 3 )  #실제 수익\n",
    "    \n",
    "    #test_x[i][bet][5].item() 이게 연승 배당률인데 정규화 되어있고 어떤 col인지 모름\n",
    "\n",
    "exp = net / len(conf_1)\n",
    "\n",
    "print(exp.item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY [124/224], 0.5536\n",
      "ACCURACY [97/224], 0.4330\n",
      "ACCURACY [70/224], 0.3125\n",
      "224\n",
      "224\n",
      "224\n",
      "1.3803573846817017\n",
      "0.9875003099441528\n",
      "ACCURACY [176/288], 0.6111\n",
      "ACCURACY [127/288], 0.4410\n",
      "ACCURACY [100/288], 0.3472\n",
      "288\n",
      "288\n",
      "288\n",
      "1.440278172492981\n",
      "1.0225698947906494\n",
      "ACCURACY [190/320], 0.5938\n",
      "ACCURACY [164/320], 0.5125\n",
      "ACCURACY [107/320], 0.3344\n",
      "320\n",
      "320\n",
      "320\n",
      "1.1684377193450928\n",
      "0.9625002145767212\n",
      "ACCURACY [241/416], 0.5793\n",
      "ACCURACY [213/416], 0.5120\n",
      "ACCURACY [148/416], 0.3558\n",
      "416\n",
      "416\n",
      "416\n",
      "1.0663461685180664\n",
      "1.0079333782196045\n",
      "ACCURACY [490/832], 0.5889\n",
      "ACCURACY [445/832], 0.5349\n",
      "ACCURACY [323/832], 0.3882\n",
      "832\n",
      "832\n",
      "832\n",
      "1.2743990421295166\n",
      "1.006249189376831\n",
      "ACCURACY [96/160], 0.6000\n",
      "ACCURACY [79/160], 0.4938\n",
      "ACCURACY [63/160], 0.3937\n",
      "160\n",
      "160\n",
      "160\n",
      "1.5418751239776611\n",
      "1.100000023841858\n",
      "ACCURACY [239/416], 0.5745\n",
      "ACCURACY [213/416], 0.5120\n",
      "ACCURACY [170/416], 0.4087\n",
      "416\n",
      "416\n",
      "416\n",
      "1.0002402067184448\n",
      "1.0055292844772339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(len(test_data_saved)):\n",
    "    conf_1 = r_train(TX[k], TY[k], model_1st, 1, 7, criterion, optimizer_1, num_epochs, 1) \n",
    "    conf_2 = r_train(TX[k], TY[k], model_2nd, 2, 7, criterion, optimizer_2, num_epochs, 1) \n",
    "    conf_3 = r_train(TX[k], TY[k], model_3rd, 3, 7, criterion, optimizer_3, num_epochs, 1) \n",
    "    print(len(conf_1))\n",
    "    print(len(conf_2))\n",
    "    print(len(conf_3))\n",
    "\n",
    "    net = 0\n",
    "    exp = 0\n",
    "\n",
    "    #단승 기대 수익률\n",
    "    for i in range(len(conf_1)):\n",
    "        temp = []\n",
    "        for j in range(len(conf_1[i])):\n",
    "            temp.append(conf_1[i][j])\n",
    "\n",
    "        temp = torch.Tensor(temp)\n",
    "        for j in range(len(temp)):\n",
    "            temp[j] = temp[j] #* TZ[k][i][j][0].item() \n",
    "        bet = temp.argmax(0).item()\n",
    "\n",
    "        net += TZ[k][i][j][0].item() * ( TY[k][i][bet] < 2 )  #실제 수익\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    exp = net / len(conf_1)\n",
    "\n",
    "    print(exp.item())\n",
    "\n",
    "    net = 0\n",
    "    exp = 0\n",
    "\n",
    "    #연승 기대 수익률\n",
    "    for i in range(len(conf_1)):\n",
    "\n",
    "        temp = []\n",
    "        for j in range(len(conf_1[i])):\n",
    "            temp.append(1-(1-conf_1[i][j])*(1-conf_2[i][j])*(1-conf_2[i][j]))\n",
    "\n",
    "        temp = torch.Tensor(temp)\n",
    "        for j in range(len(temp)):\n",
    "            temp[j] = temp[j] #* TZ[k][i][j][1].item() \n",
    "        bet = temp.argmax(0).item()\n",
    "\n",
    "\n",
    "        net += TZ[k][i][j][1].item()  * ( TY[k][i][bet] <= 3 )  #실제 수익\n",
    "\n",
    "\n",
    "\n",
    "    exp = net / len(conf_1)\n",
    "\n",
    "    print(exp.item())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
